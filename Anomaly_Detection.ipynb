{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from loaddata import load_data\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score, recall_score, roc_auc_score, fowlkes_mallows_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_num</th>\n",
       "      <th>cycle_time</th>\n",
       "      <th>os1</th>\n",
       "      <th>os2</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>sensor_09</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>sensor_12</th>\n",
       "      <th>sensor_13</th>\n",
       "      <th>sensor_14</th>\n",
       "      <th>sensor_15</th>\n",
       "      <th>sensor_17</th>\n",
       "      <th>sensor_20</th>\n",
       "      <th>sensor_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.506568</td>\n",
       "      <td>108.807862</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>642.680934</td>\n",
       "      <td>1590.523119</td>\n",
       "      <td>1408.933782</td>\n",
       "      <td>553.367711</td>\n",
       "      <td>2388.096652</td>\n",
       "      <td>9065.242941</td>\n",
       "      <td>47.541168</td>\n",
       "      <td>521.413470</td>\n",
       "      <td>2388.096152</td>\n",
       "      <td>8143.752722</td>\n",
       "      <td>8.442146</td>\n",
       "      <td>393.210654</td>\n",
       "      <td>38.816271</td>\n",
       "      <td>23.289705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.227633</td>\n",
       "      <td>68.880990</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.500053</td>\n",
       "      <td>6.131150</td>\n",
       "      <td>9.000605</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>0.070985</td>\n",
       "      <td>22.082880</td>\n",
       "      <td>0.267087</td>\n",
       "      <td>0.737553</td>\n",
       "      <td>0.071919</td>\n",
       "      <td>19.076176</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>1.548763</td>\n",
       "      <td>0.180746</td>\n",
       "      <td>0.108251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008700</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>641.210000</td>\n",
       "      <td>1571.040000</td>\n",
       "      <td>1382.250000</td>\n",
       "      <td>549.850000</td>\n",
       "      <td>2387.900000</td>\n",
       "      <td>9021.730000</td>\n",
       "      <td>46.850000</td>\n",
       "      <td>518.690000</td>\n",
       "      <td>2387.880000</td>\n",
       "      <td>8099.940000</td>\n",
       "      <td>8.324900</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>38.140000</td>\n",
       "      <td>22.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>642.325000</td>\n",
       "      <td>1586.260000</td>\n",
       "      <td>1402.360000</td>\n",
       "      <td>552.810000</td>\n",
       "      <td>2388.050000</td>\n",
       "      <td>9053.100000</td>\n",
       "      <td>47.350000</td>\n",
       "      <td>520.960000</td>\n",
       "      <td>2388.040000</td>\n",
       "      <td>8133.245000</td>\n",
       "      <td>8.414900</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>23.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>642.640000</td>\n",
       "      <td>1590.100000</td>\n",
       "      <td>1408.040000</td>\n",
       "      <td>553.440000</td>\n",
       "      <td>2388.090000</td>\n",
       "      <td>9060.660000</td>\n",
       "      <td>47.510000</td>\n",
       "      <td>521.480000</td>\n",
       "      <td>2388.090000</td>\n",
       "      <td>8140.540000</td>\n",
       "      <td>8.438900</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>38.830000</td>\n",
       "      <td>23.297900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>1594.380000</td>\n",
       "      <td>1414.555000</td>\n",
       "      <td>554.010000</td>\n",
       "      <td>2388.140000</td>\n",
       "      <td>9069.420000</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>521.950000</td>\n",
       "      <td>2388.140000</td>\n",
       "      <td>8148.310000</td>\n",
       "      <td>8.465600</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>38.950000</td>\n",
       "      <td>23.366800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>644.530000</td>\n",
       "      <td>1616.910000</td>\n",
       "      <td>1441.490000</td>\n",
       "      <td>556.060000</td>\n",
       "      <td>2388.560000</td>\n",
       "      <td>9244.590000</td>\n",
       "      <td>48.530000</td>\n",
       "      <td>523.380000</td>\n",
       "      <td>2388.560000</td>\n",
       "      <td>8293.720000</td>\n",
       "      <td>8.584800</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>39.430000</td>\n",
       "      <td>23.618400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           unit_num    cycle_time           os1           os2     sensor_02  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000  20631.000000   \n",
       "mean      51.506568    108.807862     -0.000009      0.000002    642.680934   \n",
       "std       29.227633     68.880990      0.002187      0.000293      0.500053   \n",
       "min        1.000000      1.000000     -0.008700     -0.000600    641.210000   \n",
       "25%       26.000000     52.000000     -0.001500     -0.000200    642.325000   \n",
       "50%       52.000000    104.000000      0.000000      0.000000    642.640000   \n",
       "75%       77.000000    156.000000      0.001500      0.000300    643.000000   \n",
       "max      100.000000    362.000000      0.008700      0.000600    644.530000   \n",
       "\n",
       "          sensor_03     sensor_04     sensor_07     sensor_08     sensor_09  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000  20631.000000   \n",
       "mean    1590.523119   1408.933782    553.367711   2388.096652   9065.242941   \n",
       "std        6.131150      9.000605      0.885092      0.070985     22.082880   \n",
       "min     1571.040000   1382.250000    549.850000   2387.900000   9021.730000   \n",
       "25%     1586.260000   1402.360000    552.810000   2388.050000   9053.100000   \n",
       "50%     1590.100000   1408.040000    553.440000   2388.090000   9060.660000   \n",
       "75%     1594.380000   1414.555000    554.010000   2388.140000   9069.420000   \n",
       "max     1616.910000   1441.490000    556.060000   2388.560000   9244.590000   \n",
       "\n",
       "          sensor_11     sensor_12     sensor_13     sensor_14     sensor_15  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000  20631.000000   \n",
       "mean      47.541168    521.413470   2388.096152   8143.752722      8.442146   \n",
       "std        0.267087      0.737553      0.071919     19.076176      0.037505   \n",
       "min       46.850000    518.690000   2387.880000   8099.940000      8.324900   \n",
       "25%       47.350000    520.960000   2388.040000   8133.245000      8.414900   \n",
       "50%       47.510000    521.480000   2388.090000   8140.540000      8.438900   \n",
       "75%       47.700000    521.950000   2388.140000   8148.310000      8.465600   \n",
       "max       48.530000    523.380000   2388.560000   8293.720000      8.584800   \n",
       "\n",
       "          sensor_17     sensor_20     sensor_21  \n",
       "count  20631.000000  20631.000000  20631.000000  \n",
       "mean     393.210654     38.816271     23.289705  \n",
       "std        1.548763      0.180746      0.108251  \n",
       "min      388.000000     38.140000     22.894200  \n",
       "25%      392.000000     38.700000     23.221800  \n",
       "50%      393.000000     38.830000     23.297900  \n",
       "75%      394.000000     38.950000     23.366800  \n",
       "max      400.000000     39.430000     23.618400  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.getcwd()\n",
    "path = os.path.join(dirname, \"CMAPSSData\")\n",
    "dc = load_data(path=path)\n",
    "df = dc['FD_001']['df_train'].copy()\n",
    "na_list = df.columns[df.isna().any()].tolist()\n",
    "const_list = [col for col in df.columns if len(df[col].unique()) <= 2] \n",
    "df.drop(columns=na_list+const_list,axis=1, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_num</th>\n",
       "      <th>cycle_time</th>\n",
       "      <th>os1</th>\n",
       "      <th>os2</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>sensor_09</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>sensor_12</th>\n",
       "      <th>sensor_13</th>\n",
       "      <th>sensor_14</th>\n",
       "      <th>sensor_15</th>\n",
       "      <th>sensor_17</th>\n",
       "      <th>sensor_20</th>\n",
       "      <th>sensor_21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>392</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>392</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>390</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>392</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>393</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_num  cycle_time     os1     os2  sensor_02  sensor_03  sensor_04  \\\n",
       "0         1           1 -0.0007 -0.0004     641.82    1589.70    1400.60   \n",
       "1         1           2  0.0019 -0.0003     642.15    1591.82    1403.14   \n",
       "2         1           3 -0.0043  0.0003     642.35    1587.99    1404.20   \n",
       "3         1           4  0.0007  0.0000     642.35    1582.79    1401.87   \n",
       "4         1           5 -0.0019 -0.0002     642.37    1582.85    1406.22   \n",
       "\n",
       "   sensor_07  sensor_08  sensor_09  sensor_11  sensor_12  sensor_13  \\\n",
       "0     554.36    2388.06    9046.19      47.47     521.66    2388.02   \n",
       "1     553.75    2388.04    9044.07      47.49     522.28    2388.07   \n",
       "2     554.26    2388.08    9052.94      47.27     522.42    2388.03   \n",
       "3     554.45    2388.11    9049.48      47.13     522.86    2388.08   \n",
       "4     554.00    2388.06    9055.15      47.28     522.19    2388.04   \n",
       "\n",
       "   sensor_14  sensor_15  sensor_17  sensor_20  sensor_21  RUL  \n",
       "0    8138.62     8.4195        392      39.06    23.4190  191  \n",
       "1    8131.49     8.4318        392      39.00    23.4236  190  \n",
       "2    8133.23     8.4178        390      38.95    23.3442  189  \n",
       "3    8133.83     8.3682        392      38.88    23.3739  188  \n",
       "4    8133.80     8.4294        393      38.90    23.4044  187  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = df[\"unit_num\"].unique().tolist()\n",
    "dicti = {}\n",
    "for i in units:\n",
    "    dicti[i] = df[df[\"unit_num\"] == i][\"cycle_time\"].max() \n",
    "df[\"RUL\"] = df[\"unit_num\"].apply(lambda key: dicti[key]) - df[\"cycle_time\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "20626    1\n",
       "20627    1\n",
       "20628    1\n",
       "20629    1\n",
       "20630    1\n",
       "Name: RUL_clf, Length: 20631, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"RUL_clf\"] = [1 if i <= 40 else 0 for i in df[\"RUL\"] ]\n",
    "df[\"RUL_clf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEJCAYAAABR4cpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAfUElEQVR4nO3df3RT9f3H8WfahKKGr7WYUGSMzalzp53glo2hWzqd0pa2A6Ns0gq6yZjdRPBHsVDWrhx76rCDTrd6dHI8HqUbnT9axTS4owJCnaf0TByKZ8KAIy1rk7ZIWywkab5/IBlFi7W3SSi8Hudw0vvJvbnvzzkhr9zPJ/deUygUCiEiImJAXKwLEBGRkU9hIiIihilMRETEMIWJiIgYpjARERHDFCYiImKYwkRERAwzx7qAWOns7KGvT6fYiIgMRlyciQsuOG/A58/aMOnrCylMRESGiYa5RETEMIWJiIgYpjARERHDFCYiImKYwkRERAxTmIiIiGEKExERMeysPc/EqDH/N5rRCZZYlyGnmd4jfroO9ca6DJGoU5gM0egEC7lL1sa6DDnNVK/MowuFiZx9NMwlIiKGRTxMuru7yc7OZv/+/QD885//5Cc/+QlZWVncc889HD16FICdO3ficrlIT0+nqKiIQCAAQEtLC3l5eWRkZJCfn09PTw8Ahw4dYsGCBWRmZpKXl4fX6410V0REZAARDZPt27czZ84c9u7dCxwLloULF7JixQpefvllAJ599lkACgoKKC4uZsOGDYRCIWpqagAoLS0lNzcXj8dDamoqVVVVAFRWVuJwOKivr2f27NmUlZVFsisiInIKEQ2TmpoaSkpKsNvtAGzdupUpU6Zw+eWXA7B8+XKuv/56mpub6e3tZcqUKQC4XC48Hg9+v5/GxkbS09P7tQNs3LiRnJwcALKzs9m8eTN+vz+S3RERkQFEdAL+5KOFffv2ce6553L33Xfzn//8h29961sUFhby3nvvYbPZwuvZbDZaW1vp7OzEarViNpv7tQO0tbWFtzGbzVitVjo6Ohg3blwkuyQiIp8hqr/mCgaDbNmyhXXr1nHRRRdRVFTE448/zlVXXYXJZAqvFwqFMJlM4ccTnbx84jZxcYM/0Bo71jq0Toh8DpttTKxLEIm6qIbJhRdeyOTJk5k4cSIAmZmZPPPMM7hcrn4T6D6fD7vdTlJSEl1dXQSDQeLj4/F6veEhM7vdjs/nIzk5mUAgQE9PD4mJiYOupb2929D9TPSBIQPxertiXYLIsIuLM53yS3hUfxr8/e9/n3fffZcDBw4A8Prrr5OSksKECRNISEigqakJgLq6OpxOJxaLBYfDgdvtBqC2than0wlAWloatbW1ALjdbhwOBxaLTiIUEYmFqB6ZjB8/nhUrVnDHHXdw5MgRvvGNb3D//fcDUFFRwfLly+nu7iYlJYV58+YBUFJSQmFhIY8++ijjx49n1apVACxatIjCwkKysrIYM2YMFRUV0eyKiIicwBQKhc7Ke9cOxzCXzoCXk1WvzNMwl5yRTqthLhEROTMpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETEsomHS3d1NdnY2+/fv79f+zDPPMHfu3PByS0sLeXl5ZGRkkJ+fT09PDwCHDh1iwYIFZGZmkpeXF75P/NGjRykoKCAzM5MbbriB3bt3R7IbIiLyOSIWJtu3b2fOnDns3bu3X/uuXbt4/PHH+7WVlpaSm5uLx+MhNTWVqqoqACorK3E4HNTX1zN79mzKysoAePrppznnnHOor69n2bJlLF26NFLdEBGRQYhYmNTU1FBSUoLdbg+3HT16lOLiYu66665wm9/vp7GxkfT0dABcLhcejweAjRs3kpOTA0B2djabN2/G7/ezceNGfvzjHwPwne98h46ODlpaWiLVFRER+RzmSL3w8aOIE/3+97/nxhtv5Etf+lK4rbOzE6vVitl8rBSbzUZraysAbW1t2Gy2Y4WazVitVjo6Ovq1H9/mv//9LxdddFGkuiMiIqcQsTA52datWzlw4ABLly7lrbfeCreHQiFMJlO/dU9ePnHduLi4T21zvP2LGDvW+oXWFxksm21MrEsQibqohcn69ev54IMPmDlzJocPH8bn87F48WIeeughurq6CAaDxMfH4/V6w0Njdrsdn89HcnIygUCAnp4eEhMTGTduHG1tbXz5y18GwOfz9RtOG4z29m76+kJD7o8+MGQgXm9XrEsQGXZxcaZTfgmP2k+Dy8vLqa+vp66ujgceeIDU1FQqKyuxWCw4HA7cbjcAtbW1OJ1OANLS0qitrQXA7XbjcDiwWCykpaVRV1cHwLZt20hISNAQl4hIDJ0W55mUlJRQU1PDjBkz2LZtG4sXLwZg0aJFvP3222RlZVFdXU1xcTEAc+fO5ejRo2RlZVFWVsbKlStjWb6IyFnPFAqFhj7WM4INxzBX7pK1w1iRnAmqV+ZpmEvOSKfNMJeIiJy5FCYiImKYwkRERAxTmIiIiGEKExERMUxhIiIihilMRETEMIWJiIgYpjARERHDFCYiImKYwkRERAxTmIiIiGEKExERMUxhIiIihilMRETEMIWJiIgYFvEw6e7uJjs7m/379wOwbt06srOzycnJYenSpRw9ehSAnTt34nK5SE9Pp6ioiEAgAEBLSwt5eXlkZGSQn59PT08PAIcOHWLBggVkZmaSl5eH1+uNdFdERGQAEQ2T7du3M2fOHPbu3QvAnj17WLNmDX/961958cUX6evro7q6GoCCggKKi4vZsGEDoVCImpoaAEpLS8nNzcXj8ZCamkpVVRUAlZWVOBwO6uvrmT17NmVlZZHsioiInEJEw6SmpoaSkhLsdjsAo0aNoqSkBKvVislk4rLLLqOlpYXm5mZ6e3uZMmUKAC6XC4/Hg9/vp7GxkfT09H7tABs3biQnJweA7OxsNm/ejN/vj2R3RERkAOZIvvjJRwsTJkxgwoQJAHR0dLB27VrKy8tpa2vDZrOF17PZbLS2ttLZ2YnVasVsNvdrB/ptYzabsVqtdHR0MG7cuEh2SUREPkNEw2Qgra2tzJ8/nxtvvJGpU6fS1NSEyWQKPx8KhTCZTOHHE528fOI2cXGDP9AaO9Y6tOJFPofNNibWJYhEXdTDZPfu3cyfP5+5c+fy85//HIDk5OR+E+g+nw+73U5SUhJdXV0Eg0Hi4+Pxer3hITO73Y7P5yM5OZlAIEBPTw+JiYmDrqO9vZu+vtCQ+6EPDBmI19sV6xJEhl1cnOmUX8Kj+tPg7u5ubr/9dhYtWhQOEjg2/JWQkEBTUxMAdXV1OJ1OLBYLDocDt9sNQG1tLU6nE4C0tDRqa2sBcLvdOBwOLBZLNLsjIiKfiGqYPPvss/h8Pp588klmzpzJzJkz+cMf/gBARUUF5eXlZGRkcPjwYebNmwdASUkJNTU1zJgxg23btrF48WIAFi1axNtvv01WVhbV1dUUFxdHsysiInICUygUGvpYzwg2HMNcuUvWDmNFciaoXpmnYS45I51Ww1wiInJmUpiIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJiWMTDpLu7m+zsbPbv3w9AQ0MDOTk5TJ8+ndWrV4fX27lzJy6Xi/T0dIqKiggEAgC0tLSQl5dHRkYG+fn59PT0AHDo0CEWLFhAZmYmeXl5/e4hLyIi0RXRMNm+fTtz5sxh7969APT29rJs2TKqqqpwu93s2LGDTZs2AVBQUEBxcTEbNmwgFApRU1MDQGlpKbm5uXg8HlJTU6mqqgKgsrISh8NBfX09s2fPpqysLJJdERGRU4homNTU1FBSUoLdbgfgnXfeYdKkSUycOBGz2UxOTg4ej4fm5mZ6e3uZMmUKAC6XC4/Hg9/vp7GxkfT09H7tABs3biQnJweA7OxsNm/ejN/vj2R3RERkAOZIvvjJRwttbW3YbLbwst1up7W19VPtNpuN1tZWOjs7sVqtmM3mfu0nv5bZbMZqtdLR0cG4ceMi2SUREfkMEQ2Tk/X19WEymcLLoVAIk8k0YPvxxxOdvHziNnFxgz/QGjvW+gWrFxkcm21MrEsQibqohklycnK/iXKv14vdbv9Uu8/nw263k5SURFdXF8FgkPj4+PD6cOyoxufzkZycTCAQoKenh8TExEHX0t7eTV9faMh90QeGDMTr7Yp1CSLDLi7OdMov4VH9afDkyZPZs2cP+/btIxgMsn79epxOJxMmTCAhIYGmpiYA6urqcDqdWCwWHA4HbrcbgNraWpxOJwBpaWnU1tYC4Ha7cTgcWCyWaHZHREQ+EdUjk4SEBB588EEWLlzIkSNHSEtLIyMjA4CKigqWL19Od3c3KSkpzJs3D4CSkhIKCwt59NFHGT9+PKtWrQJg0aJFFBYWkpWVxZgxY6ioqIhmV0RE5ASmUCj0uWM9ra2tn5rY3rVrF5dccknECou04Rjmyl2ydhgrkjNB9co8DXPJGcnQMNfBgwc5ePAgv/jFL/joo4/Cyz6fjzvvvHPYixURkZHplMNc9957L1u3bgVg6tSp/9vIbA6f+yEiInLKMFmzZg0AS5cupby8PCoFiYjIyDOoCfjy8nKam5v56KOPOHGKJSUlJWKFiYjIyDGoMHn44YdZs2YNY8eODbeZTCZeffXViBUmIiIjx6DCpLa2lldeeUWXKhERkc80qJMWx48fryAREZEBDerIZNq0aaxcuZIf/ehHjB49OtyuORMREYFBhsnzzz8PEL78O2jORERE/mdQYfLaa69Fug4RERnBBhUmTz755Ge2/+xnPxvWYkREZGQaVJj8+9//Dv999OhRGhsbmTZtWsSKEhGRkWXQJy2eqLW1laKioogUJCIiI8+Q7mcybtw4mpubh7sWEREZob7wnEkoFGLHjh39zoYXEZGz2xeeM4FjJzEuWbIkIgWJiMjI84XmTJqbmwkEAkyaNMnQTuvq6nj88ccBcDqd3H///ezcuZOioiJ6enpwOByUlpZiNptpaWmhoKCA9vZ2vvrVr1JRUcF5553HoUOHuO+++/jwww9JSkqisrISm81mqC4RERmaQc2Z7Nu3j6ysLGbNmoXL5eK6665j9+7dQ9rhxx9/TFlZGU8//TR1dXVs27aNhoYGCgoKKC4uZsOGDYRCIWpqagAoLS0lNzcXj8dDamoqVVVVAFRWVuJwOKivr2f27NmUlZUNqR4RETFuUGGyYsUK5s+fT2NjI01NTeTn51NaWjqkHQaDQfr6+vj4448JBAIEAgHMZjO9vb1MmTIFAJfLhcfjwe/309jYGL4R1/F2gI0bN5KTkwNAdnY2mzdvxu/3D6kmERExZlBh0t7ezg033BBevvHGG+ns7BzSDq1WK4sWLSIzM5O0tDQmTJiAxWLpN0Rls9lobW2ls7MTq9WK2Wzu1w7Q1tYW3sZsNmO1Wuno6BhSTSIiYsyg5kyCwSAHDx4kMTERwNCH9vvvv89zzz3H66+/zpgxY7jvvvvYunUrJpMpvE4oFMJkMoUfT3Ty8onbxMUN/pfOY8dah9YBkc9hs42JdQkiUTeoMLnlllv46U9/SmZmJiaTCbfbza233jqkHW7ZsoVp06aFf1rscrlYs2YNXq83vI7P58Nut5OUlERXVxfBYJD4+Hi8Xi92ux0Au92Oz+cjOTmZQCBAT09POOwGo729m76+0OevOAB9YMhAvN6uWJcgMuzi4kyn/BI+qK/yaWlpAPj9fnbv3k1rayvXX3/9kAq6/PLLaWho4PDhw4RCIV577TW++93vkpCQQFNTE3Ds115OpxOLxYLD4cDtdgPHbtLldDrDNdXW1gLgdrtxOBxYLJYh1SQiIsaYQife1H0At912G9deey3z5s3jyJEj/OUvf2Hr1q38+c9/HtJOH3/8cZ5//nksFgvf/OY3KSkpYc+ePSxfvpzu7m5SUlIoLy9n1KhRNDc3U1hYSHt7O+PHj2fVqlWcf/75HDx4kMLCQj788EPGjBlDRUUFX/rSlwZdw3AcmeQuWTvk7eXMVL0yT0cmckb6vCOTQYXJzJkzqaur69c2a9as8JHBSKQwkUhQmMiZaliGuYLBYPhXVHBsTmMQGSQiImeJQU3A33bbbcyaNYsf/OAHmEwmGhoadDkVEREJG1SY3HTTTaSmpvKPf/yD+Ph4br/9di677LJI1yYiIiPEoMIEjv0K6/LLL49kLSIiMkIN6X4mIiIiJ1KYiIiIYQoTERExTGEiIiKGKUxERMQwhYmIiBimMBEREcMUJiIiYpjCREREDFOYiIiIYQoTERExTGEiIiKGxSRMXnvtNVwuF5mZmTzwwAMANDQ0kJOTw/Tp01m9enV43Z07d+JyuUhPT6eoqIhAIABAS0sLeXl5ZGRkkJ+fT09PTyy6IiIixCBMPvzwQ0pKSqiqquLFF1/kvffeY9OmTSxbtoyqqircbjc7duxg06ZNABQUFFBcXMyGDRsIhULU1NQAUFpaSm5uLh6Ph9TUVKqqqqLdFRER+UTUw+Tvf/87M2bMIDk5GYvFwurVqznnnHOYNGkSEydOxGw2k5OTg8fjobm5md7eXqZMmQKAy+XC4/Hg9/tpbGwkPT29X7uIiMTGoO9nMlz27duHxWLhjjvu4MCBA/zwhz/k0ksvxWazhdex2+20trbS1tbWr91ms9Ha2kpnZydWqxWz2dyvXUREYiPqYRIMBtm2bRtPP/005557Lvn5+YwePRqTyRReJxQKYTKZ6Ovr+8z2448nOnn584wdazXWEZEB2GxjYl2CSNRFPUwuvPBCpk2bRlJSEgDXXXcdHo+H+Pj48Dperxe73U5ycjJerzfc7vP5sNvtJCUl0dXVRTAYJD4+Prz+F9He3k1fX2jI/dAHhgzE6+2KdQkiwy4uznTKL+FRnzO55ppr2LJlC4cOHSIYDPLGG2+QkZHBnj172LdvH8FgkPXr1+N0OpkwYQIJCQk0NTUBUFdXh9PpxGKx4HA4cLvdANTW1uJ0OqPdFRER+UTUj0wmT57M/Pnzyc3Nxe/3c/XVVzNnzhwuvvhiFi5cyJEjR0hLSyMjIwOAiooKli9fTnd3NykpKcybNw+AkpISCgsLefTRRxk/fjyrVq2KdldEROQTplAoNPSxnhFsOIa5cpesHcaK5ExQvTJPw1xyRjrthrlEROTMozARERHDFCYiImKYwkRERAxTmIiIiGEKExERMUxhIiIihilMRETEMIWJiIgYpjARERHDFCYiImKYwkRERAxTmIiIiGEKExERMUxhIiIihilMRETEMIWJiIgYFtMw+d3vfkdhYSEAO3fuxOVykZ6eTlFREYFAAICWlhby8vLIyMggPz+fnp4eAA4dOsSCBQvIzMwkLy8Pr9cbs36IiJztYhYmb775Ji+88EJ4uaCggOLiYjZs2EAoFKKmpgaA0tJScnNz8Xg8pKamUlVVBUBlZSUOh4P6+npmz55NWVlZTPohIiJgjsVODx48yOrVq7njjjt4//33aW5upre3lylTpgDgcrl4+OGHmT17No2NjfzpT38Kt99yyy0UFBSwceNG1q49dg/27OxsVqxYgd/vx2KxxKJLIqeVC84fhXlUQqzLkNNM4OgROj86GpHXjkmYFBcXc/fdd3PgwAEA2trasNls4edtNhutra10dnZitVoxm8392k/exmw2Y7Va6ejoYNy4cYOqYexY63B2SSTMZhsT6xIAaFo5P9YlyGnm20uewGaLzJeMqIfJ3/72N8aPH8+0adN4/vnnAejr68NkMoXXCYVCmEym8OOJTl4+cZu4uMGP2rW3d9PXFxpCD445XT4w5PTj9XbFugS9P2VAQ31/xsWZTvklPOph4na78Xq9zJw5k48++ojDhw9jMpn6TaD7fD7sdjtJSUl0dXURDAaJj4/H6/Vit9sBsNvt+Hw+kpOTCQQC9PT0kJiYGO3uiIgIMZiAf/LJJ1m/fj11dXXcddddXHvttZSXl5OQkEBTUxMAdXV1OJ1OLBYLDocDt9sNQG1tLU6nE4C0tDRqa2uBYwHlcDg0XyIiEiOnzXkmFRUVlJeXk5GRweHDh5k3bx4AJSUl1NTUMGPGDLZt28bixYsBWLRoEW+//TZZWVlUV1dTXFwcy/JFRM5qplAoNPSJgxFsOOZMcpesHcaK5ExQvTLvtJkz0QS8nOzbS56I2JzJaXNkIiIiI5fCREREDFOYiIiIYQoTERExTGEiIiKGKUxERMQwhYmIiBimMBEREcMUJiIiYpjCREREDFOYiIiIYQoTERExTGEiIiKGKUxERMQwhYmIiBimMBEREcNiEiZ//OMfycrKIisri5UrVwLQ0NBATk4O06dPZ/Xq1eF1d+7cicvlIj09naKiIgKBAAAtLS3k5eWRkZFBfn4+PT09seiKiIgQgzBpaGhgy5YtvPDCC9TW1vLuu++yfv16li1bRlVVFW63mx07drBp0yYACgoKKC4uZsOGDYRCIWpqagAoLS0lNzcXj8dDamoqVVVV0e6KiIh8IuphYrPZKCwsZNSoUVgsFr72ta+xd+9eJk2axMSJEzGbzeTk5ODxeGhubqa3t5cpU6YA4HK58Hg8+P1+GhsbSU9P79cuIiKxYY72Di+99NLw33v37qW+vp5bbrkFm80Wbrfb7bS2ttLW1tav3Waz0draSmdnJ1arFbPZ3K/9izjVvYxFjLDZxsS6BJEBRer9GfUwOe6DDz7gl7/8JUuWLCE+Pp69e/eGnwuFQphMJvr6+jCZTJ9qP/54opOXP097ezd9faEh168PDBmI19sV6xL0/pQBDfX9GRdnOuWX8JhMwDc1NXHbbbdx7733csMNN5CcnIzX6w0/7/V6sdvtn2r3+XzY7XaSkpLo6uoiGAz2W19ERGIj6mFy4MABfv3rX1NRUUFWVhYAkydPZs+ePezbt49gMMj69etxOp1MmDCBhIQEmpqaAKirq8PpdGKxWHA4HLjdbgBqa2txOp3R7oqIiHwi6sNca9as4ciRIzz44IPhtptvvpkHH3yQhQsXcuTIEdLS0sjIyACgoqKC5cuX093dTUpKCvPmzQOgpKSEwsJCHn30UcaPH8+qVaui3RUREfmEKRQKDX3iYAQbjjmT3CVrh7EiORNUr8w7beZMmlbOj3UZcpr59pInzqw5ExERObMoTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETFsRIfJSy+9xIwZM5g+fTpr1+pGVSIisRL12/YOl9bWVlavXs3zzz/PqFGjuPnmm5k6dSqXXHJJrEsTETnrjNgwaWho4Hvf+x6JiYkApKen4/F4uPPOOwe1fVycyXANF15wnuHXkDPPcLy3hsOo/xsb6xLkNDTU9+fnbTdiw6StrQ2bzRZettvtvPPOO4Pe/oJhCIKHl84y/Bpy5jnVfbKj6Zt3/C7WJchpKFLvzxE7Z9LX14fJ9L+kDIVC/ZZFRCR6RmyYJCcn4/V6w8terxe73R7DikREzl4jNkyuuuoq3nzzTTo6Ovj444955ZVXcDqdsS5LROSsNGLnTMaNG8fdd9/NvHnz8Pv93HTTTVxxxRWxLktE5KxkCoVCoVgXISIiI9uIHeYSEZHTh8JEREQMU5iIiIhhChMRETFMYSKG6GKbcjrr7u4mOzub/fv3x7qUM57CRIbs+MU2q6urqa2tZd26dezatSvWZYkAsH37dubMmcPevXtjXcpZQWEiQ3bixTbPPffc8MU2RU4HNTU1lJSU6MoYUTJiT1qU2DN6sU2RSCorK4t1CWcVHZnIkOlimyJynMJEhkwX2xSR4xQmMmS62KaIHKc5ExkyXWxTRI7ThR5FRMQwDXOJiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIgZ8/etfJycnh5kzZzJr1izS09O58cYb+de//gXAW2+9RXZ29qe2W7FiBY888ggAhYWFrFmzZljqeeSRR1ixYgUAW7Zs4ZprruGmm26it7d3WF5fZCA6aVHEoKeeeoqkpKTw8po1a3jggQdYt25dDKuCl19+mdmzZ/OrX/0qpnXI2UFhIjKMAoEABw4c4Pzzz4/4fh566CE2btxIfHw8V155JSUlJeHnn3jiCV599VUSEhLo6uri/vvvj2g9IgoTEYNuvfVWADo7O0lISOCaa66hvLw8ovusrq7m3Xffpa6ujlGjRnHPPffgdrvDz8+fP59du3Zx6aWXcvvtt0e0FhHQnImIYU899RQvvfQSjz32GL29vUydOpWxY8cCEBf32f/F+vr6BnxuMBoaGpg5cyajR48mLi6OyspKZs2aNeTXEzFKYSIyTFJSUli6dCmFhYXhe45fcMEFHDx48FPrtre3k5iYOOR9mc39BxV8Ph9tbW1Dfj0RoxQmIsMoOzubK664IjzMdfHFFzNq1Kh+Q1C7du3irbfe4uqrrx7yfqZNm8b69es5evQofX19/Pa3v+Xll182XL/IUClMRIbZb37zGzZt2sQbb7xBXFwcjz32GM899xw5OTlkZ2ezbNkyVq5cyVe+8pXwNqtXr+bKK68M/7vnnntOuY+bb76ZlJQUXC4XOTk52Gw25s6dG+GeiQxMl6AXERHD9GsukdNQd3c3eXl5n/nceeedR3V1dZQrEjk1HZmIiIhhmjMRERHDFCYiImKYwkRERAxTmIiIiGEKExERMez/ARytjiEGNG2LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    16531\n",
      "1     4100\n",
      "Name: RUL_clf, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sns.countplot(x=\"RUL_clf\",data=df)\n",
    "plt.show()\n",
    "print(df[\"RUL_clf\"].value_counts())\n",
    "df.drop(\"RUL\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_model_metrics(model,actual,predicted):\n",
    "    \n",
    "    clf_metrics = {\n",
    "                        \"Adjusted Rand Score\": adjusted_rand_score(actual, predicted),\n",
    "                        \"Fowlkes Mallows Score\":fowlkes_mallows_score(actual, predicted),\n",
    "                        \"Recall Score\": recall_score(actual, predicted),\n",
    "                        \"Auc Score\": roc_auc_score(actual, predicted),     \n",
    "                  }\n",
    "    \n",
    "    df_clf_metrics = pd.DataFrame.from_dict(clf_metrics, orient='index')\n",
    "    df_clf_metrics.columns = [model]\n",
    "    \n",
    "    return df_clf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, data):\n",
    "    \n",
    "    \n",
    "    X = df.drop([\"os1\",\"os2\",\"RUL_clf\",\"sensor_14\"],axis=1)\n",
    "    y = df[\"RUL_clf\"].values\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for name, clf in model.items():\n",
    "        print(\"Fitting model: \" + name)\n",
    "        clf.fit(X)\n",
    "        \n",
    "        if name == \"K-Means\":\n",
    "            y_pred = clf.predict(X)\n",
    "            y_pred = (y_pred == 0).astype(int)\n",
    "            \n",
    "        elif name == \"Auto Encoder\":\n",
    "            y_pred = clf.predict(X)\n",
    "            \n",
    "        else:\n",
    "            y_pred = clf.predict(X)\n",
    "            y_pred = (y_pred == -1).astype(int)\n",
    "            \n",
    "        if i == 0:\n",
    "            metrics = get_clf_model_metrics(name, y, y_pred)\n",
    "            print(metrics)\n",
    "            \n",
    "        elif i != 0:\n",
    "            new_metric = get_clf_model_metrics(name, y, y_pred)\n",
    "            print(new_metric)\n",
    "            metrics = pd.concat([metrics, new_metric],axis=1)\n",
    "            \n",
    "        i= i+1\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {    \n",
    "     \"One Class SVM\": OneClassSVM(),\n",
    "     \"Local Outlier Factor\": LocalOutlierFactor(contamination=0.248, novelty=True),\n",
    "     \"K-Means\": KMeans(n_clusters = 2, random_state = 42),\n",
    "     \"Isolation Forest\": IsolationForest(n_estimators=100, random_state=42, n_jobs=-1, contamination=0.248),\n",
    "     \"Auto Encoder\": AutoEncoder(hidden_neurons =[20, 12, 12, 20],contamination = 0.248),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model: One Class SVM\n",
      "                       One Class SVM\n",
      "Adjusted Rand Score         0.027017\n",
      "Fowlkes Mallows Score       0.595300\n",
      "Recall Score                0.707317\n",
      "Auc Score                   0.629262\n",
      "\n",
      "\n",
      "\n",
      "Fitting model: Local Outlier Factor\n",
      "                       Local Outlier Factor\n",
      "Adjusted Rand Score                0.005806\n",
      "Fowlkes Mallows Score              0.666761\n",
      "Recall Score                       0.237317\n",
      "Auc Score                          0.506143\n",
      "\n",
      "\n",
      "\n",
      "Fitting model: K-Means\n",
      "                        K-Means\n",
      "Adjusted Rand Score    0.252667\n",
      "Fowlkes Mallows Score  0.695814\n",
      "Recall Score           0.963171\n",
      "Auc Score              0.832623\n",
      "\n",
      "\n",
      "\n",
      "Fitting model: Isolation Forest\n",
      "                       Isolation Forest\n",
      "Adjusted Rand Score            0.370995\n",
      "Fowlkes Mallows Score          0.782479\n",
      "Recall Score                   0.690000\n",
      "Auc Score                      0.775797\n",
      "\n",
      "\n",
      "\n",
      "Fitting model: Auto Encoder\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                320       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 12)                252       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 20)                260       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 1,783\n",
      "Trainable params: 1,783\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 18567 samples, validate on 2064 samples\n",
      "Epoch 1/100\n",
      "18567/18567 [==============================] - 2s 91us/step - loss: 13.6789 - val_loss: 4.3927\n",
      "Epoch 2/100\n",
      "18567/18567 [==============================] - 1s 66us/step - loss: 3.3469 - val_loss: 2.6209\n",
      "Epoch 3/100\n",
      "18567/18567 [==============================] - 1s 70us/step - loss: 2.3454 - val_loss: 2.0509\n",
      "Epoch 4/100\n",
      "18567/18567 [==============================] - 1s 59us/step - loss: 1.9270 - val_loss: 1.7575\n",
      "Epoch 5/100\n",
      "18567/18567 [==============================] - 1s 52us/step - loss: 1.6852 - val_loss: 1.5708\n",
      "Epoch 6/100\n",
      "18567/18567 [==============================] - 1s 61us/step - loss: 1.5232 - val_loss: 1.4392\n",
      "Epoch 7/100\n",
      "18567/18567 [==============================] - 1s 70us/step - loss: 1.4045 - val_loss: 1.3409\n",
      "Epoch 8/100\n",
      "18567/18567 [==============================] - 1s 74us/step - loss: 1.3137 - val_loss: 1.2654\n",
      "Epoch 9/100\n",
      "18567/18567 [==============================] - 1s 70us/step - loss: 1.2432 - val_loss: 1.2057\n",
      "Epoch 10/100\n",
      "18567/18567 [==============================] - 1s 67us/step - loss: 1.1879 - val_loss: 1.1584\n",
      "Epoch 11/100\n",
      "18567/18567 [==============================] - 1s 63us/step - loss: 1.1438 - val_loss: 1.1207\n",
      "Epoch 12/100\n",
      "18567/18567 [==============================] - 1s 71us/step - loss: 1.1086 - val_loss: 1.0909\n",
      "Epoch 13/100\n",
      "18567/18567 [==============================] - 1s 64us/step - loss: 1.0813 - val_loss: 1.0676\n",
      "Epoch 14/100\n",
      "18567/18567 [==============================] - 1s 57us/step - loss: 1.0601 - val_loss: 1.0495\n",
      "Epoch 15/100\n",
      "18567/18567 [==============================] - 1s 63us/step - loss: 1.0439 - val_loss: 1.0357\n",
      "Epoch 16/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0316 - val_loss: 1.0254\n",
      "Epoch 17/100\n",
      "18567/18567 [==============================] - 1s 57us/step - loss: 1.0226 - val_loss: 1.0178\n",
      "Epoch 18/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0161 - val_loss: 1.0123\n",
      "Epoch 19/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0114 - val_loss: 1.0084\n",
      "Epoch 20/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0081 - val_loss: 1.0057\n",
      "Epoch 21/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0058 - val_loss: 1.0038\n",
      "Epoch 22/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0042 - val_loss: 1.0024\n",
      "Epoch 23/100\n",
      "18567/18567 [==============================] - 1s 57us/step - loss: 1.0030 - val_loss: 1.0015\n",
      "Epoch 24/100\n",
      "18567/18567 [==============================] - 1s 58us/step - loss: 1.0022 - val_loss: 1.0008\n",
      "Epoch 25/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0017 - val_loss: 1.0003\n",
      "Epoch 26/100\n",
      "18567/18567 [==============================] - 1s 53us/step - loss: 1.0013 - val_loss: 1.0000\n",
      "Epoch 27/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0010 - val_loss: 0.9998\n",
      "Epoch 28/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0008 - val_loss: 0.9996\n",
      "Epoch 29/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0006 - val_loss: 0.9994\n",
      "Epoch 30/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0005 - val_loss: 0.9993\n",
      "Epoch 31/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0004 - val_loss: 0.9993\n",
      "Epoch 32/100\n",
      "18567/18567 [==============================] - 1s 54us/step - loss: 1.0003 - val_loss: 0.9992\n",
      "Epoch 33/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0003 - val_loss: 0.9992\n",
      "Epoch 34/100\n",
      "18567/18567 [==============================] - 1s 54us/step - loss: 1.0002 - val_loss: 0.9991\n",
      "Epoch 35/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0002 - val_loss: 0.9991\n",
      "Epoch 36/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0002 - val_loss: 0.9991\n",
      "Epoch 37/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0002 - val_loss: 0.9991\n",
      "Epoch 38/100\n",
      "18567/18567 [==============================] - 1s 54us/step - loss: 1.0002 - val_loss: 0.9991\n",
      "Epoch 39/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0002 - val_loss: 0.9990\n",
      "Epoch 40/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0002 - val_loss: 0.9990\n",
      "Epoch 41/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 42/100\n",
      "18567/18567 [==============================] - 1s 54us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 43/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 44/100\n",
      "18567/18567 [==============================] - 1s 57us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 45/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 46/100\n",
      "18567/18567 [==============================] - 1s 55us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 47/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 48/100\n",
      "18567/18567 [==============================] - 1s 56us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 50/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 51/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 52/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 53/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 54/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 55/100\n",
      "18567/18567 [==============================] - 1s 47us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 56/100\n",
      "18567/18567 [==============================] - 1s 48us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 57/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 58/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 59/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 60/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 61/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 62/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 63/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 64/100\n",
      "18567/18567 [==============================] - 1s 47us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 65/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 66/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 67/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 68/100\n",
      "18567/18567 [==============================] - 1s 48us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 69/100\n",
      "18567/18567 [==============================] - 1s 47us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 70/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 71/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 72/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 73/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 74/100\n",
      "18567/18567 [==============================] - 1s 48us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 75/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 76/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 77/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 78/100\n",
      "18567/18567 [==============================] - 1s 48us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 79/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 80/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 81/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 82/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 83/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 84/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 85/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 86/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 87/100\n",
      "18567/18567 [==============================] - 1s 48us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 88/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 89/100\n",
      "18567/18567 [==============================] - 1s 48us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 90/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 91/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 92/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 93/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 94/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 95/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 96/100\n",
      "18567/18567 [==============================] - 1s 48us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 97/100\n",
      "18567/18567 [==============================] - 1s 48us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 98/100\n",
      "18567/18567 [==============================] - 1s 50us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 99/100\n",
      "18567/18567 [==============================] - 1s 49us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "Epoch 100/100\n",
      "18567/18567 [==============================] - 1s 51us/step - loss: 1.0001 - val_loss: 0.9990\n",
      "                       Auto Encoder\n",
      "Adjusted Rand Score        0.385371\n",
      "Fowlkes Mallows Score      0.787471\n",
      "Recall Score               0.702439\n",
      "Auc Score                  0.783559\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>One Class SVM</th>\n",
       "      <th>Local Outlier Factor</th>\n",
       "      <th>K-Means</th>\n",
       "      <th>Isolation Forest</th>\n",
       "      <th>Auto Encoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adjusted Rand Score</th>\n",
       "      <td>0.027017</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.252667</td>\n",
       "      <td>0.370995</td>\n",
       "      <td>0.385371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fowlkes Mallows Score</th>\n",
       "      <td>0.595300</td>\n",
       "      <td>0.666761</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.782479</td>\n",
       "      <td>0.787471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.237317</td>\n",
       "      <td>0.963171</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.702439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auc Score</th>\n",
       "      <td>0.629262</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>0.832623</td>\n",
       "      <td>0.775797</td>\n",
       "      <td>0.783559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       One Class SVM  Local Outlier Factor   K-Means  \\\n",
       "Adjusted Rand Score         0.027017              0.005806  0.252667   \n",
       "Fowlkes Mallows Score       0.595300              0.666761  0.695814   \n",
       "Recall Score                0.707317              0.237317  0.963171   \n",
       "Auc Score                   0.629262              0.506143  0.832623   \n",
       "\n",
       "                       Isolation Forest  Auto Encoder  \n",
       "Adjusted Rand Score            0.370995      0.385371  \n",
       "Fowlkes Mallows Score          0.782479      0.787471  \n",
       "Recall Score                   0.690000      0.702439  \n",
       "Auc Score                      0.775797      0.783559  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model(model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
